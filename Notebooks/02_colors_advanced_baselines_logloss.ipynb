{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fd12b0",
   "metadata": {},
   "source": [
    "# Artificial Vision & Feature Separability — 02 · Colors (Advanced Baselines & Log-Loss)\n",
    "\n",
    "**Goal.** Strengthen baselines for color categorization with **log-loss**, **regularization**, **class imbalance handling**, and **calibration**.  \n",
    "**Models.** Multinomial Logistic Regression (C & penalty sweeps), Prototype, k-NN, and GCM.  \n",
    "**Evaluation.** Accuracy, **log-loss**, confusion matrices, **calibration curves**, and **ROC-AUC (OvR)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f643b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility & Environment ---\n",
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "print(\"Seed set to\", SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a31d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, accuracy_score, log_loss,\n",
    "    roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffb9f8",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "Load from `data/colors.csv` (columns like `R,G,B,label` or `L,a,b,label`) **or** generate an imbalanced toy RGB set to test robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: CSV loader\n",
    "csv_path = Path(\"data/colors.csv\")\n",
    "if csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    feat_cols = [c for c in df.columns if c.lower() in [\"r\",\"g\",\"b\",\"l\",\"a\",\"b\"]][:3]\n",
    "    assert len(feat_cols)==3, \"Expect 3 feature columns (RGB or Lab).\"\n",
    "else:\n",
    "    # Option B: imbalanced toy RGB data (red is majority)\n",
    "    def make_toy_colors_imbalanced(seed=SEED):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        centers = {\n",
    "            \"red\":   (np.array([220, 40, 40]), 600),\n",
    "            \"green\": (np.array([40, 220, 40]), 200),\n",
    "            \"blue\":  (np.array([40, 40, 220]), 200),\n",
    "        }\n",
    "        X_list, y_list = [], []\n",
    "        for label, (c, n) in centers.items():\n",
    "            Xc = rng.normal(c, 30, size=(n, 3)).clip(0,255)\n",
    "            X_list.append(Xc); y_list += [label]*n\n",
    "        X = np.vstack(X_list).astype(np.float32)\n",
    "        y = np.array(y_list)\n",
    "        return pd.DataFrame({\"R\":X[:,0], \"G\":X[:,1], \"B\":X[:,2], \"label\":y})\n",
    "    df = make_toy_colors_imbalanced()\n",
    "    feat_cols = [\"R\",\"G\",\"B\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd4a176",
   "metadata": {},
   "source": [
    "## 2. Split, Scale, and Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747014c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feat_cols].values\n",
    "y = df[\"label\"].values\n",
    "labels = sorted(np.unique(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xz_train = scaler.fit_transform(X_train)\n",
    "Xz_test  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \" Test size:\", X_test.shape[0], \" Classes:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf51fa",
   "metadata": {},
   "source": [
    "## 3. Multinomial Logistic Regression — **C** & Penalty Sweep\n",
    "We sweep **C** (inverse regularization strength) and compare `l2` vs `l1` (if solver supports it).  \n",
    "We track **accuracy** and **log-loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48bf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": np.logspace(-3, 2, 8),\n",
    "    \"penalty\": [\"l2\"],  # can add \"l1\" with solver=\"saga\"\n",
    "    \"solver\": [\"lbfgs\"],  # \"saga\" supports l1+l2 but is slower\n",
    "    \"multi_class\": [\"multinomial\"],\n",
    "    \"max_iter\": [1000],\n",
    "}\n",
    "\n",
    "base = LogisticRegression(random_state=SEED)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "gs = GridSearchCV(base, param_grid, scoring=\"neg_log_loss\", cv=cv, n_jobs=-1, refit=True, verbose=0)\n",
    "gs.fit(Xz_train, y_train)\n",
    "\n",
    "best_lr = gs.best_estimator_\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "print(\"Best CV log-loss:\", -gs.best_score_)\n",
    "\n",
    "pred = best_lr.predict(Xz_test)\n",
    "proba = best_lr.predict_proba(Xz_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "ll = log_loss(y_test, proba, labels=labels)\n",
    "cm = confusion_matrix(y_test, pred, labels=labels)\n",
    "print(f\"Test Accuracy: {acc:.3f}  |  Test Log-loss: {ll:.3f}\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cm, aspect=\"auto\")\n",
    "plt.title(\"Confusion — Best Logistic Regression\")\n",
    "plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n",
    "plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.colorbar(); plt.tight_layout(); plt.savefig(\"results/02_confusion_logreg_best.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83cef0",
   "metadata": {},
   "source": [
    "## 4. Prototype & Exemplar Revisited (for comparison)\n",
    "Prototype classifier on standardized space; k-NN and GCM exemplar models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4efd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype\n",
    "centroids = {lab: Xz_train[y_train==lab].mean(axis=0) for lab in labels}\n",
    "def proto_predict(Xz):\n",
    "    preds = []\n",
    "    for row in Xz:\n",
    "        d2 = {lab: np.linalg.norm(row - mu) for lab, mu in centroids.items()}\n",
    "        preds.append(min(d2, key=d2.get))\n",
    "    return np.array(preds)\n",
    "\n",
    "pred_proto = proto_predict(Xz_test)\n",
    "acc_proto = accuracy_score(y_test, pred_proto)\n",
    "cm_proto = confusion_matrix(y_test, pred_proto, labels=labels)\n",
    "print(f\"Prototype — Acc: {acc_proto:.3f}\")\n",
    "\n",
    "# k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(Xz_train, y_train)\n",
    "pred_knn = knn.predict(Xz_test)\n",
    "proba_knn = knn.predict_proba(Xz_test)\n",
    "acc_knn = accuracy_score(y_test, pred_knn)\n",
    "ll_knn = log_loss(y_test, proba_knn, labels=labels)\n",
    "print(f\"k-NN — Acc: {acc_knn:.3f} | Log-loss: {ll_knn:.3f}\")\n",
    "\n",
    "# GCM exemplar\n",
    "def gcm_predict_proba(Xz, Xz_train, y_train, labels, c=2.0):\n",
    "    proba = np.zeros((Xz.shape[0], len(labels)), dtype=float)\n",
    "    lab2idx = {lab:i for i,lab in enumerate(labels)}\n",
    "    for i, row in enumerate(Xz):\n",
    "        d = Xz_train - row\n",
    "        dist = np.linalg.norm(d, axis=1)\n",
    "        sim = np.exp(-c * dist)\n",
    "        # accumulate per class\n",
    "        for s, lab in zip(sim, y_train):\n",
    "            proba[i, lab2idx[lab]] += s\n",
    "        # normalize\n",
    "        ssum = proba[i].sum()\n",
    "        if ssum > 0: proba[i] /= ssum\n",
    "    return proba\n",
    "\n",
    "proba_gcm = gcm_predict_proba(Xz_test, Xz_train, y_train, labels, c=2.0)\n",
    "pred_gcm = np.array([labels[i] for i in np.argmax(proba_gcm, axis=1)])\n",
    "acc_gcm = accuracy_score(y_test, pred_gcm)\n",
    "ll_gcm = log_loss(y_test, proba_gcm, labels=labels)\n",
    "print(f\"GCM — Acc: {acc_gcm:.3f} | Log-loss: {ll_gcm:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99166cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrices\n",
    "for name, yhat in [\n",
    "    (\"prototype\", pred_proto),\n",
    "    (\"knn\", pred_knn),\n",
    "    (\"gcm\", pred_gcm),\n",
    "]:\n",
    "    cm_ = confusion_matrix(y_test, yhat, labels=labels)\n",
    "    plt.figure(); plt.imshow(cm_, aspect=\"auto\")\n",
    "    plt.title(f\"Confusion — {name}\")\n",
    "    plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.colorbar(); plt.tight_layout(); plt.savefig(f\"results/02_confusion_{name}.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec444e5",
   "metadata": {},
   "source": [
    "## 5. Calibration Analysis\n",
    "Plot reliability curves (true vs predicted probability) for the best logistic and k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration(y_true, proba, labels, title, path):\n",
    "    # reduce to max-class probability for a simple reliability curve\n",
    "    # (for multi-class, more advanced plots per-class or ECE can be added)\n",
    "    y_true_bin = (y_true == labels[0]).astype(int)  # choose a reference class for demo\n",
    "    p_ref = proba[:, 0]  # probability of class labels[0]\n",
    "    frac_pos, mean_pred = calibration_curve(y_true_bin, p_ref, n_bins=10, strategy=\"uniform\")\n",
    "    plt.figure()\n",
    "    plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], \"--\", alpha=0.5)\n",
    "    plt.xlabel(\"Mean predicted probability\")\n",
    "    plt.ylabel(\"Fraction of positives\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout(); plt.savefig(path, dpi=150); plt.show()\n",
    "\n",
    "# Logistic\n",
    "proba_lr = best_lr.predict_proba(Xz_test)\n",
    "plot_calibration(y_test, proba_lr, labels, \"Calibration — Logistic (class 0 ref)\", \"results/02_calibration_logreg.png\")\n",
    "\n",
    "# k-NN\n",
    "plot_calibration(y_test, proba_knn, labels, \"Calibration — k-NN (class 0 ref)\", \"results/02_calibration_knn.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e7c2b",
   "metadata": {},
   "source": [
    "## 6. ROC-AUC (One-vs-Rest)\n",
    "Compute macro-average ROC-AUC using OvR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize labels for OvR\n",
    "lab2idx = {lab:i for i,lab in enumerate(labels)}\n",
    "y_test_bin = np.array([lab2idx[lab] for lab in y_test])\n",
    "\n",
    "# For scikit's multi-class ROC-AUC, pass probas and labels\n",
    "auc_lr  = roc_auc_score(y_test, proba_lr, multi_class=\"ovr\", labels=labels)\n",
    "auc_knn = roc_auc_score(y_test, proba_knn, multi_class=\"ovr\", labels=labels)\n",
    "auc_gcm = roc_auc_score(y_test, proba_gcm, multi_class=\"ovr\", labels=labels)\n",
    "\n",
    "print(f\"ROC-AUC (OvR) — Logistic: {auc_lr:.3f} | k-NN: {auc_knn:.3f} | GCM: {auc_gcm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f4b8f",
   "metadata": {},
   "source": [
    "## 7. Decision Illustrations (2D PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = PCA(n_components=2, random_state=SEED)\n",
    "Z_train = p2.fit_transform(Xz_train)\n",
    "Z_test  = p2.transform(Xz_test)\n",
    "\n",
    "def plot_boundary(model, Z_tr, y_tr, title, outpath):\n",
    "    # Fit on 2D to draw clean boundaries\n",
    "    model.fit(Z_tr, y_tr)\n",
    "    xmin, ymin = Z_tr.min(axis=0) - 1\n",
    "    xmax, ymax = Z_tr.max(axis=0) + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(xmin, xmax, 200), np.linspace(ymin, ymax, 200))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    pred = model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    def label_to_int(arr, labels):\n",
    "        mapping = {lab:i for i,lab in enumerate(labels)}\n",
    "        return np.vectorize(mapping.get)(arr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, label_to_int(pred, labels), alpha=0.3)\n",
    "    plt.scatter(Z_tr[:,0], Z_tr[:,1], c=label_to_int(y_tr, labels), s=10, edgecolor='k', linewidth=0.2)\n",
    "    plt.title(title); plt.tight_layout(); plt.savefig(outpath, dpi=150); plt.show()\n",
    "\n",
    "plot_boundary(LogisticRegression(max_iter=1000, multi_class=\"multinomial\", random_state=SEED),\n",
    "              Z_train, y_train, \"Decision — Logistic (2D PCA)\", \"results/02_boundary_logistic_2d.png\")\n",
    "\n",
    "plot_boundary(KNeighborsClassifier(n_neighbors=5),\n",
    "              Z_train, y_train, \"Decision — k-NN (2D PCA)\", \"results/02_boundary_knn_2d.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b925b9",
   "metadata": {},
   "source": [
    "## 8. Takeaways\n",
    "- **Log-loss** is a stricter metric than accuracy and is improved via **regularization tuning** (C-sweep).\n",
    "- Prototype and exemplar models provide interpretable baselines; exemplar (k-NN/GCM) often improves log-loss on complex boundaries.\n",
    "- **Calibration** matters when comparing probabilistic models; k-NN can be overconfident/underconfident depending on k.\n",
    "- Macro **ROC-AUC (OvR)** provides class-balanced performance insight for imbalanced data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
