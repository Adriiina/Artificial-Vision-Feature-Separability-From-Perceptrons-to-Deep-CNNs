{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345d9ba4",
   "metadata": {},
   "source": [
    "# Artificial Vision & Feature Separability — 05 · Perceptron & Linear Separability\n",
    "\n",
    "**Goal.** Implement the classic **Perceptron** algorithm, study **linear separability**, and compare against **logistic regression** on toy and real-ish datasets.  \n",
    "**Outputs.** Decision boundaries, learning curves, margin diagnostics, and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility & Environment ---\n",
    "import os, random, numpy as np\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "print(\"Seed set to\", SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82aa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08730eb6",
   "metadata": {},
   "source": [
    "## 1. Data — Linearly Separable vs Non-separable\n",
    "We generate a clearly separable set and a slightly overlapping set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separable\n",
    "X_sep, y_sep = make_blobs(n_samples=600, centers=2, cluster_std=0.7, random_state=SEED)\n",
    "y_sep = y_sep*2 - 1  # convert to {-1, +1} for perceptron\n",
    "# Non-separable\n",
    "X_non, y_non = make_classification(n_samples=600, n_features=2, n_redundant=0, n_informative=2,\n",
    "                                   n_clusters_per_class=1, class_sep=0.6, flip_y=0.1, random_state=SEED)\n",
    "y_non = y_non*2 - 1\n",
    "\n",
    "# Standardize for stability\n",
    "sc_sep = StandardScaler().fit(X_sep);  Z_sep = sc_sep.transform(X_sep)\n",
    "sc_non = StandardScaler().fit(X_non);  Z_non = sc_non.transform(X_non)\n",
    "\n",
    "print(\"Shapes:\", Z_sep.shape, Z_non.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3a7fb",
   "metadata": {},
   "source": [
    "## 2. Perceptron (from scratch)\n",
    "We implement the online Perceptron update \\( w \\leftarrow w + y_i x_i \\) when a point is misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea863618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(X, y, epochs=20, lr=1.0, shuffle=True, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    w = np.zeros(X.shape[1])\n",
    "    b = 0.0\n",
    "    history = []\n",
    "    for ep in range(epochs):\n",
    "        idx = np.arange(len(X))\n",
    "        if shuffle:\n",
    "            rng.shuffle(idx)\n",
    "        mistakes = 0\n",
    "        for i in idx:\n",
    "            if y[i]*(np.dot(w, X[i]) + b) <= 0:\n",
    "                w += lr * y[i] * X[i]\n",
    "                b += lr * y[i]\n",
    "                mistakes += 1\n",
    "        history.append(mistakes)\n",
    "    return w, b, history\n",
    "\n",
    "def perceptron_predict(X, w, b):\n",
    "    return np.sign(X @ w + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b554118",
   "metadata": {},
   "source": [
    "### 2.1 Train on separable vs non-separable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba937b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_s, b_s, hist_s = perceptron_train(Z_sep, y_sep)\n",
    "w_n, b_n, hist_n = perceptron_train(Z_non, y_non)\n",
    "\n",
    "print(\"Final mistakes per epoch (separable):\", hist_s[-5:])\n",
    "print(\"Final mistakes per epoch (non-separable):\", hist_n[-5:])\n",
    "\n",
    "plt.figure(); plt.plot(hist_s, label=\"separable\"); plt.plot(hist_n, label=\"non-separable\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"# mistakes\"); plt.legend(); plt.title(\"Perceptron mistakes per epoch\")\n",
    "plt.tight_layout(); plt.savefig(\"results/05_perceptron_mistakes.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb830f",
   "metadata": {},
   "source": [
    "## 3. Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14568b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(ax, X, y, w, b, title):\n",
    "    ax.scatter(X[:,0], X[:,1], c=(y>0).astype(int), s=12, edgecolor='k', linewidth=0.2)\n",
    "    xs = np.linspace(X[:,0].min()-1, X[:,0].max()+1, 200)\n",
    "    if abs(w[1]) > 1e-8:\n",
    "        ys = -(w[0]*xs + b)/w[1]\n",
    "        ax.plot(xs, ys, 'k-')\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "plot_boundary(axes[0], Z_sep, y_sep, w_s, b_s, \"Separable (Perceptron)\")\n",
    "plot_boundary(axes[1], Z_non, y_non, w_n, b_n, \"Non-separable (Perceptron)\")\n",
    "plt.tight_layout(); plt.savefig(\"results/05_perceptron_boundaries.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d6940",
   "metadata": {},
   "source": [
    "## 4. Compare with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sep = LogisticRegression().fit(Z_sep, (y_sep>0).astype(int))\n",
    "log_non = LogisticRegression().fit(Z_non, (y_non>0).astype(int))\n",
    "\n",
    "pred_sep_lr = log_sep.predict(Z_sep)\n",
    "pred_non_lr = log_non.predict(Z_non)\n",
    "\n",
    "acc_sep_lr = accuracy_score((y_sep>0).astype(int), pred_sep_lr)\n",
    "acc_non_lr = accuracy_score((y_non>0).astype(int), pred_non_lr)\n",
    "\n",
    "print(f\"Logistic Acc — separable: {acc_sep_lr:.3f}, non-separable: {acc_non_lr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_line_logreg(clf, X):\n",
    "    xs = np.linspace(X[:,0].min()-1, X[:,0].max()+1, 200)\n",
    "    w = clf.coef_[0]; b = clf.intercept_[0]\n",
    "    ys = -(w[0]*xs + b)/w[1]\n",
    "    return xs, ys\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "axes[0].scatter(Z_sep[:,0], Z_sep[:,1], c=(y_sep>0).astype(int), s=12, edgecolor='k', linewidth=0.2)\n",
    "xs, ys = decision_line_logreg(log_sep, Z_sep); axes[0].plot(xs, ys, 'r-'); axes[0].set_title(\"Separable (Logistic)\")\n",
    "axes[1].scatter(Z_non[:,0], Z_non[:,1], c=(y_non>0).astype(int), s=12, edgecolor='k', linewidth=0.2)\n",
    "xs, ys = decision_line_logreg(log_non, Z_non); axes[1].plot(xs, ys, 'r-'); axes[1].set_title(\"Non-separable (Logistic)\")\n",
    "plt.tight_layout(); plt.savefig(\"results/05_logreg_boundaries.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41568d5d",
   "metadata": {},
   "source": [
    "## 5. Margin Diagnostics (optional)\n",
    "Perceptron converges if data are linearly separable with margin \\(\\gamma\\). We estimate a proxy margin along the learned direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_proxy(X, y, w, b):\n",
    "    margins = y * (X @ w + b) / (np.linalg.norm(w) + 1e-8)\n",
    "    return margins.min(), margins.mean()\n",
    "\n",
    "m_min_sep, m_mean_sep = margin_proxy(Z_sep, y_sep, w_s, b_s)\n",
    "m_min_non, m_mean_non = margin_proxy(Z_non, y_non, w_n, b_n)\n",
    "print(f\"Margin proxy — separable: min={m_min_sep:.3f}, mean={m_mean_sep:.3f}\")\n",
    "print(f\"Margin proxy — non-separable: min={m_min_non:.3f}, mean={m_mean_non:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3670f",
   "metadata": {},
   "source": [
    "## 6. Takeaways\n",
    "- Perceptron **converges** on linearly separable data; on non-separable data, mistakes persist.\n",
    "- Logistic regression provides a **probabilistic linear** baseline and often handles slight overlap better.\n",
    "- Visualizing boundaries highlights **linear separability limits** — sets up the move to MLP/CNN."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
